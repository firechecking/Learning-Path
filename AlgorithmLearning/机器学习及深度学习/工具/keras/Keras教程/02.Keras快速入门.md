# Keras快速入门
## 惯序模型使用入门
### 定义惯序模型
惯序模型是层的线性排列模型，可以通过传递一个层的list来创建

```python
from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential([
    Dense(32, input_shape=(784,)),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])
```
也可以通过.add()函数来创建

```python
model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
```
### 定义输入数据形状
模型需要知道输入数据的形状，因此惯序模型的第一层需要接受输入数据形状（只有第一层需要，后续层会自动完成数据形状计算），可以有以下方法来定义输入数据形状：
* 使用input_shape参数来定义：input_shape是一个整数的tuple类型，input_shape中，不包括batch维数；
* 如全连接Dense等二维层，支持input_dim参数，一些三维层支持input_dim和input_length参数；
* 如果需要制定batch size，可以制定batch_size参数，如果同时制定batch_size=32, input_shape=(6,8)，那么每批输入都有如下形状（32,6,8）

以下定义作用相同：
```python
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
```
```python
model = Sequential()
model.add(Dense(32, input_dim=784))
```
### 编译
在开始训练之前，需要先通过compile方法来定义学习过程，compile方法接收以下三个参数：
* 优化器：可以是预定义的优化器string（如rmsprop、adagrad）或一个优化器对象（Optimizer类的实例）；
* 损失函数：损失函数是模型尝试最小化的对象，可以是预定义的损失函数string（如categorical_crossentropy或mse）或一个函数对象
* 性能评估函数：需要传递一个性能评估函数列表，性能评估是为了直观地了解算法的效果，并不参与到优化过程。对于任何分类问题，通常设置metrics=['accuracy']，性能评估函数可以是已存在的评估函数string，或者一个自定义的metric函数。

```python
# For a multi-class classification problem
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# For a binary classification problem
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# For a mean squared error regression problem
model.compile(optimizer='rmsprop',
              loss='mse')

# For custom metrics
import keras.backend as K

def mean_pred(y_true, y_pred):
    return K.mean(y_pred)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy', mean_pred])
```
### 训练
Keras模型以numpy arrays格式接收训练数据和训练标签，通常使用fit函数完成训练。

```
# For a single-input model with 2 classes (binary classification):

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Generate dummy data
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, labels, epochs=10, batch_size=32)
```

```
# For a single-input model with 10 classes (categorical classification):

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Generate dummy data
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(10, size=(1000, 1))

# Convert labels to categorical one-hot encoding
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
```
### 实例
以下是一些简单的实例，在examples目录，还可以找到更多使用真实数据的实例：
* CIFAR10小批量图片分类：CNN
* IMDB电源评论分类：LSTM
* Reuters新闻分类：MLP
* MNIST手写数字识别：MLP & CNN
* 基于LSTM的文本生成

## Keras功能API使用入门
Keras功能API可以用于定义复杂的模型，如多输出模型、共享层模型等。

### 样例一：全连接网络
惯序模型可以很好的表示全连接网络，本节采用全连接网络是为了更方便的说明。
* 层的实例是可调用的，并且接受tensor作为输入，并返回一个tensor作为输出；
* 输入tensor和输出tensor可用于定义一个model
* 定义好的模型可以采用类似惯序模型的方式进行训练

```python
from keras.layers import Input, Dense
from keras.models import Model

# 返回一个（?,784）的tensor
inputs = Input(shape=(784,))

# 层对象可以以tensor作为输入进行调用，其返回值也是一个tensor
x = Dense(64, activation='relu')(inputs)
x = Dense(64, activation='relu')(x) 
predictions = Dense(10, activation='softmax')(x)

# 创建一个model，其具有1个输入层，3个全连接层
# the Input layer and three Dense layers 
model = Model(inputs=inputs, outputs=predictions) 
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(data, labels) # starts training
```
### 模型和层都是可调用的
在是用Keras model时，可以很方便的对模型进行复用：模型和层一样，都可以以tensor作为输入进行调用。在复用模型时，不仅使用了它的结构，也将重用它的权重。

```python
x = Input(shape=(784,))
# 通过以下调用，按上文定义，可以对输入进行10分类
y = model(x)
```
模型的复用特性，可以很方便的将一个图片分类模型转换成视频分类模型：
```python
from keras.layers import TimeDistributed

# 输入序列包含10帧画面，每一帧是784维的向量
input_sequences = Input(shape=(20, 784))

# 将上文的模型运用到输入序列的每一帧，因为模型输出为10维的softmax分类器，因此下面语句的输入是（20，10）的数组
processed_sequences = TimeDistributed(model)(input_sequences)
```

### 多输入多输出模型
具有多输入多输出的模型，是运用Keras功能API的一个强大功能。
考虑以下模型，我们要预测一个头条新闻在twitter上的转发数和喜欢数，模型的主要输入是头条新闻本身（一个词序列），同时，模型还有一些辅助的输入，如头条发布时间等，模型还需要2个损失函数。模型结构如下：

![](https://s3.amazonaws.com/keras.io/img/multi-input-multi-output-graph.png)

main_input接收头条内容，格式为整数序列（每一个整数代表一个词），整数取值范围为1-10000，序列长度为100。

```python
from keras.layers import Input, Embedding, LSTM, Dense 
from keras.models import Model

# main_input接收长度100的整数序列
main_input = Input(shape=(100,), dtype='int32', name='main_input') 

# embedding层将输入序列编码成521维向量序列
x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input) 

# LSTM层将向量序列转换成一个向量
lstm_out = LSTM(32)(x)

# 然后添加一个辅助损失函数，使LSTM和Embedding层可以较平滑地进行训练
auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)

# 将LSTM输出和辅助输入结合在一起作为后续模型的输入
auxiliary_input = Input(shape=(5,), name='aux_input')
x = keras.layers.concatenate([lstm_out, auxiliary_input])

x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)

main_output = Dense(1, activation='sigmoid', name='main_output')(x)

# 然后定义一个双输入双输出模型：
model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])

# 然后调用.compile对模型进行编译，可以通过一个字典或列表来制定不同的loss_weights和loss
model.compile(optimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1., 0.2])

# 调用fit进行模型训练
model.fit({'main_input': headline_data, 'aux_input': additional_data}, {'main_output': labels, 'aux_output': labels}, epochs=50, batch_size=32)
```
### 网络层共享
使用Keras功能API另一个用途是共享网络层，以判断2条tweet是否由同一个人发布为例，可以将tweet编码为向量后，将2条tweet向量合成一个向量，通过一个逻辑回归判断2条tweet属于同一个作者的概率。模型可以通过2条相同作者的tweet和不同作者的tweet进行训练。

因为对称性，2条tweet可以使用相同方式进行编码为向量，这儿使用共享的LSTM层来编码。首先接收tweet为（280，256）的向量，280表示最多280个字符，256以one-hot方式对tweet进行编码（只取了英语中最高频的256个词），代码如下：

```python
import keras
from keras.layers import Input, LSTM, Dense
from keras.models import Model
tweet_a = Input(shape=(280, 256))
tweet_b = Input(shape=(280, 256))

# 使用共享层时，只需要实例化一次，并进行任意多次的调用

# LSTM(64)接收矩阵输入，并输出一个64维的向量
shared_lstm = LSTM(64)

# 当多次调用同一个网络层时，网络层的结构和权重参数都将被复用
encoded_a = shared_lstm(tweet_a)
encoded_b = shared_lstm(tweet_b)

# 然后将2条tweet编码后的向量进行线性组合
merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)

# 添加一个逻辑回归层进行概率判断
predictions = Dense(1, activation='sigmoid')(merged_vector)

# 定义模型并训练
model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.fit([data_a, data_b], labels, epochs=10)
```
#### 层复用的内在机理
当对同一个层传递不同输入进行多次调用时，每次调用实际创建了一个新的tensor（层的输出），并添加了一个“node”到层，“node”的作用是将输入tensor和输出tensor相关联，也即是调用同一个层多次时，实际创建了多个nodes，并依次编号0,1,2...

在Keras中，可以使用layer.output_shape或layer.output来获取输出tensor。

如果一个层只与一个输入关联，那么.output会返回输出tensor：

```python
a = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)

assert lstm.output == encoded_a
```
如果一个层有多个输入时

```python
a = Input(shape=(280, 256))
b = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)
encoded_b = lstm(b)

assert lstm.get_output_at(0) == encoded_a
assert lstm.get_output_at(1) == encoded_b
```
对于input_shape和output_shape属性也是一样的，如果一个层只有一个input、output，或多个input、output具有相同的shape，那么可以使用layer.output_shape/layer.input_shape获取，否则，需要使用get_input_shape_at()获取

```
a = Input(shape=(32, 32, 3))
b = Input(shape=(64, 64, 3))

conv = Conv2D(16, (3, 3), padding='same')
conved_a = conv(a)

# Only one input so far, the following will work:
assert conv.input_shape == (None, 32, 32, 3)

conved_b = conv(b)
# now the `.input_shape` property wouldn't work, but this does:
assert conv.get_input_shape_at(0) == (None, 32, 32, 3)
assert conv.get_input_shape_at(1) == (None, 64, 64, 3)
```
### 其他examples
#### Inception模型
参考[Going Deeper with Convolutions](http://arxiv.org/abs/1409.4842).
![](https://images2017.cnblogs.com/blog/617848/201709/617848-20170902180202452-175524597.png)
```python
from keras.layers import Conv2D, MaxPooling2D, Input

input_img = Input(shape=(256, 256, 3))

tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)

tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)

tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)
tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)

output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)
```
### 残差网络
参考[Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385).

```python
from keras.layers import Conv2D, Input

# input tensor for a 3-channel 256x256 image
x = Input(shape=(256, 256, 3))
# 3x3 conv with 3 output channels (same as input channels)
y = Conv2D(3, (3, 3), padding='same')(x)
# this returns x + y.
z = keras.layers.add([x, y])
```
### 共享模型
模型在2个输入数据中复用了同一个图像处理模型，来判断MNIST数字是否是相同数字

```python
from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten
from keras.models import Model

# First, define the vision modules
digit_input = Input(shape=(27, 27, 1))
x = Conv2D(64, (3, 3))(digit_input)
x = Conv2D(64, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
out = Flatten()(x)

vision_model = Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = Input(shape=(27, 27, 1))
digit_b = Input(shape=(27, 27, 1))

# The vision model will be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = keras.layers.concatenate([out_a, out_b])
out = Dense(1, activation='sigmoid')(concatenated)

classification_model = Model([digit_a, digit_b], out)
```
### 视觉描述模型
模型可以选择一个词来回答有关给定图像的问题，其原理是将问题和图像分别编码为向量，并将2个向量组合在一起，然后在已经标注词的模型上进行逻辑回归训练。

```python
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from keras.models import Model, Sequential

# First, let's define a vision model using a Sequential model.
# This model will encode an image into a vector.
vision_model = Sequential()
vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))
vision_model.add(Conv2D(64, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(128, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Flatten())

# Now let's get a tensor with the output of our vision model:
image_input = Input(shape=(224, 224, 3))
encoded_image = vision_model(image_input)

# Next, let's define a language model to encode the question into a vector.
# Each question will be at most 100 word long,
# and we will index words as integers from 1 to 9999.
question_input = Input(shape=(100,), dtype='int32')
embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Let's concatenate the question vector and the image vector:
merged = keras.layers.concatenate([encoded_question, encoded_image])

# And let's train a logistic regression over 1000 words on top:
output = Dense(1000, activation='softmax')(merged)

# This is our final model:
vqa_model = Model(inputs=[image_input, question_input], outputs=output)

# The next stage would be training this model on actual data.
```
### 视频问答模型
上一个例子中，训练了图片的问答模型，可以将其快速的修改为视频问答模型，通过训练后的模型，可以通过给模型提供一段小视频（如100帧的运动视频），然后通过自然语言进行提问（如：Q：“男孩在进行什么运动”，A：“足球”）

```
from keras.layers import TimeDistributed

video_input = Input(shape=(100, 224, 224, 3))
# This is our video encoded via the previously trained vision_model (weights are reused)
encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors
encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector

# This is a model-level representation of the question encoder, reusing the same weights as before:
question_encoder = Model(inputs=question_input, outputs=encoded_question)

# Let's use it to encode the question:
video_question_input = Input(shape=(100,), dtype='int32')
encoded_video_question = question_encoder(video_question_input)

# And this is our video question answering model:
merged = keras.layers.concatenate([encoded_video, encoded_video_question])
output = Dense(1000, activation='softmax')(merged)
video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)
```
