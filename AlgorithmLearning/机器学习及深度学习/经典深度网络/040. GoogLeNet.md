# GoogLeNet
## 参考链接
1. <http://blog.csdn.net/app_12062011/article/details/62216987>
1. <http://blog.csdn.net/shuzfan/article/details/50738394>
1. <https://www.jianshu.com/p/33197e469414>
## 模型简介
GoogLeNet的最早版本，出现在2014年的[《Going deeper with convolutions》](http://arxiv.org/abs/1409.4842)。之所以名为“GoogLeNet”而非“GoogleNet”,文章说是为了向早期的LeNet致敬。

一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生**过拟合**也会大大增加**计算量**。

文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献[1](http://blog.csdn.net/shuzfan/article/details/50738394#fn:1x "See footnote")表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。**这点表明臃肿的稀疏网络可能被不失性能地简化。** 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。

早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了随机稀疏连接。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。

所以，现在的问题是有没有一种方法，**既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能**。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。

## 结构
**Inception** 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。 
作者首先提出下图这样的基本结构： 
![这里写图片描述](http://img.blog.csdn.net/20160225155336279)
对上图做以下说明： 
**1 .** 采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； 
**2 .** 之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；
**3 .** 文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。 
**4 .** 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。

**但是，使用5x5的卷积核仍然会带来巨大的计算量。** 为此，文章借鉴NIN[2](http://blog.csdn.net/shuzfan/article/details/50738394#fn:2x "See footnote")，采用1x1卷积核来进行**降维**。
例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。

具体改进后的Inception Module如下图： 
![这里写图片描述](http://img.blog.csdn.net/20160225155351172)

## **GoogLeNet**

GoogLeNet的整体结构如下图：

![这里写图片描述](http://img.blog.csdn.net/20160225155403967)

对上图做如下说明： 
**1 .** 显然GoogLeNet采用了模块化的结构，方便增添和修改； 
**2 .** 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；
**3 .** 虽然移除了全连接，但是网络中依然使用了Dropout ; 
**4 .** 为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际[测试](http://lib.csdn.net/base/softwaretest "软件测试知识库")的时候，这两个额外的softmax会被去掉。

下图是一个比较清晰的结构图：

![这里写图片描述](http://img.blog.csdn.net/20160225155414702)

## **Conclusion**

GoogLeNet是谷歌团队为了参加ILSVRC 2014比赛而精心准备的，为了达到最佳的性能，除了使用上述的网络结构外，还做了大量的辅助工作：包括训练多个model求平均、裁剪不同尺度的图像做多次验证等等。详细的这些可以参看文章的实验部分。

本文的主要想法其实是想通过构建密集的块结构来近似最优的稀疏结构，从而达到提高性能而又不大量增加计算量的目的。GoogleNet的caffemodel大小约50M，但性能却很优异。

## GoogLeNet V1、V2、V3、V4差异
*   Inception v1的网络，将1x1，3x3，5x5的conv和3x3的pooling，stack在一起，一方面增加了网络的width，另一方面增加了网络对尺度的适应性；
*   v2的网络在v1的基础上，进行了改进，一方面了加入了BN层，减少了Internal Covariate Shift（内部neuron的数据分布发生变化），使每一层的输出都规范化到一个N(0, 1)的高斯，另外一方面学习VGG用2个3x3的conv替代inception模块中的5x5，既降低了参数数量，也加速计算；
*   v3一个最重要的改进是分解（Factorization），将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块；
*   v4研究了Inception模块结合Residual Connection能不能有改进？发现ResNet的结构可以极大地加速训练，同时性能也有提升，得到一个Inception-ResNet v2网络，同时还设计了一个更深更优化的Inception v4模型，能达到与Inception-ResNet v2相媲美的性能

## BN网络介绍
Batch Normalization，简称BN
### 参考链接
1. <http://blog.csdn.net/app_12062011/article/details/57083447>
1. <https://www.cnblogs.com/stingsl/p/6428694.html>

### BN介绍
就像激活函数层、卷积层、全连接层、池化层一样，BN(Batch Normalization)也属于网络的一层。在前面我们提到网络除了输出层外，其它层因为低层网络在训练的时候更新了参数，而引起后面层输入数据分布的变化。这个时候我们可能就会想，如果在每一层输入的时候，再加个预处理操作那该有多好啊，比如网络第三层输入数据X3(X3表示网络第三层的输入数据)把它归一化至：均值0、方差为1，然后再输入第三层计算，这样我们就可以解决前面所提到的“Internal Covariate Shift”的问题了。

而事实上，paper的算法本质原理就是这样：在网络的每一层输入的时候，又插入了一个归一化层，也就是先做一个归一化处理，然后再进入网络的下一层。不过文献归一化层，可不像我们想象的那么简单，它是一个可学习、有参数的网络层。既然说到数据预处理，下面就先来复习一下最强的预处理方法：白化。

白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。

输入数据集X，经过白化处理后，新的数据X'满足两个性质：

1. 特征之间相关性较低；
1. 所有特征具有相同的方差。

因为白化需要计算协方差矩阵、求逆等操作，计算量很大，此外，反向传播时，白化操作不一定可导。于是，采用下面的Normalization方法来处理

数据归一化方法很简单，就是要让数据具有**0均值和单位方差**，如下式： 
![这里写图片描述](http://img.blog.csdn.net/20160223160039062)
但是作者又说如果简单的这么干，会降低层的表达能力。比如下图，在使用sigmoid激活函数的时候，如果把数据限制到0均值单位方差，那么相当于只使用了激活函数中近似线性的部分，这显然会降低模型表达能力。
![这里写图片描述](http://img.blog.csdn.net/20160223160053859)

为此，作者又为BN增加了2个参数，用来保持模型的表达能力。 
于是最后的输出为： 
![这里写图片描述](http://img.blog.csdn.net/20160223160123115)
上述公式中用到了均值E和方差Var，需要注意的是理想情况下E和Var应该是针对整个数据集的，但显然这是不现实的。因此，作者做了简化，**用一个Batch的均值和方差作为对整个数据集均值和方差的估计。**
整个BN的[算法](http://lib.csdn.net/base/datastructure "算法与数据结构知识库")如下：
![这里写图片描述](http://img.blog.csdn.net/20160223160132599)
求导的过程也非常简单，有兴趣地可以自己再推导一遍或者直接参见原文。



