# LeNet
## 模型简介
LeNet5诞生于1994年，由Yann LeCun提出，充分考虑图像的相关性。当时结构的特点如下：
	1. 每个卷积层包含三个部分：卷积（Conv）、池化（ave-pooling）、非线性激活函数（sigmoid）
	1. MLP作为最终的分类器
	1. 层与层之间稀疏连接减少计算复杂度

## 结构模型

![](http://img.blog.csdn.net/20170627093308794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcm9ndWVzaXI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

## 网络层介绍

Input Layer：1x32x32图像

Conv1 Layer：包含6个卷积核，kernal size：5x5，parameters:（5x5+1）*6=156个

Subsampling Layer：average pooling，size：2*2

Activation Function：sigmoid

Conv3 Layer：包含16个卷积核，kernal size：5*5  ->16个Feature Map

Subsampling Layer：average pooling，size：2*2

Conv5 Layer：包含120个卷积核，kernal size：5*5

Fully Connected Layer：Activation Function：sigmoid

Output Layer：Gaussian connection

## 代码实现

说明一下，原本应该放LeNet5的TensorFlow实现代码，发现LeNet5的模型在现在使用过程中好多地方进行了更改，比如激励函数换做ReLU，采用max pooling等等，因此，我只是简单地进行了一个CNN的TensorFlow代码实现，用的MNIST数据集，代码如下：

**[python]** [view plain](http://blog.csdn.net/roguesir/article/details/73770448# "view plain") [copy](http://blog.csdn.net/roguesir/article/details/73770448# "copy")

在GPU上面训练，大概不到两分钟，准确率99.11%

![](http://img.blog.csdn.net/20170627112640734?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcm9ndWVzaXI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

注：系统环境：ubuntu、Python3.5.2、TensorFlow1.2.0


